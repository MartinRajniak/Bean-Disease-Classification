{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beans Disease classification: Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to build a robust machine learning model that is able to distinguish between diseases in the Bean plants. Beans are an important cereal food crop for Africa grown by many small-holder farmers - they are a significant source of proteins for school-age going children in East Africa.\n",
    "\n",
    "The data is of leaf images representing 3 classes: the healthy class of images, and two disease classes including Angular Leaf Spot and Bean Rust diseases. The model should be able to distinguish between these 3 classes with high accuracy. The end goal is to build a robust, model that can be deployed on a mobile device and used in the field by a farmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: improve description (images?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move to source files\n",
    "\n",
    "from enum import Enum, auto\n",
    "\n",
    "class DatasetSource(Enum):\n",
    "    HUGGING_FACE = auto()\n",
    "    TENSORFLOW = auto()\n",
    "    KAGGLE = auto()\n",
    "\n",
    "class BaseModel(Enum):\n",
    "    XCEPTION = auto()\n",
    "    EFFICIENT_NET_V2 = auto()\n",
    "    MOBILE_NET = auto()\n",
    "\n",
    "class Optimizer(Enum):\n",
    "    SGD = auto()\n",
    "    ADAM = auto()\n",
    "    NADAM = auto()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: keep all configuration at the same place (temporarily here but eventually in config file)\n",
    "\n",
    "PREPROCESS_IN_MODEL = False\n",
    "\n",
    "DATASET_SOURCE = DatasetSource.TENSORFLOW\n",
    "BASE_MODEL = BaseModel.XCEPTION\n",
    "OPTIMIZER = Optimizer.SGD\n",
    "\n",
    "# Same ratio as in original dataset\n",
    "# TODO: use percentage in case we use datasets with different sizes\n",
    "TRAIN_SIZE = 1034\n",
    "VAL_SIZE = 133\n",
    "TEST_SIZE = 128\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS_PRETRAIN = 5 # 20\n",
    "EPOCHS_FINETUNE = 10 # 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: Do not use Mixed Precision for mobile - TFLite doesn't support float16 for all ops yet\n",
    "# https://ai.google.dev/edge/litert/models/ops_compatibility#supported_types\n",
    "\n",
    "# policy = tf.keras.mixed_precision.Policy(\"mixed_float16\")\n",
    "# tf.keras.mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 11:38:19.081780: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758706710.198802    3939 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2874 MB memory:  -> device: 0, name: Quadro P600, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#TODO: Download dataset from Kaggle\n",
    "if (DATASET_SOURCE == DatasetSource.TENSORFLOW\n",
    "    or DATASET_SOURCE == DatasetSource.KAGGLE):\n",
    "    import tensorflow_datasets as tfds\n",
    "elif (DATASET_SOURCE == DatasetSource.HUGGING_FACE):\n",
    "    from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, Resizing, Lambda, RandomFlip, RandomRotation, RandomContrast\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD, Adam, Nadam\n",
    "from keras.optimizers.schedules import CosineDecayRestarts\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "if (BASE_MODEL == BaseModel.XCEPTION):\n",
    "    from keras.applications.xception import Xception, preprocess_input\n",
    "elif (BASE_MODEL == BaseModel.EFFICIENT_NET_V2):\n",
    "    from keras.applications.efficientnet_v2 import EfficientNetV2S, preprocess_input\n",
    "elif (BASE_MODEL == BaseModel.MOBILE_NET):\n",
    "    from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versions\n",
    "\n",
    "Check versions for compatibility issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.20.0\n",
      "keras: 3.11.3\n",
      "scikit-learn: 1.7.2\n",
      "numpy: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "# TODO: requirements file should be enough and could replace this\n",
    "\n",
    "from importlib.metadata import version\n",
    "\n",
    "def print_version(module_name):\n",
    "    print(f\"{module_name}: {version(module_name)}\")\n",
    "\n",
    "print_version(\"tensorflow\")\n",
    "print_version(\"keras\")\n",
    "print_version(\"scikit-learn\")\n",
    "print_version(\"numpy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 24 11:38:31 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.170                Driver Version: 573.44         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Quadro P600                    On  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   64C    P0            N/A  / 5001W |      33MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            3939      C   /python3.12                           N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/bash: line 1: nvcc: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinism\n",
    "\n",
    "Make sure every run is deterministic so that results are reproducible and improvements verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed using keras.utils.set_random_seed. This will set:\n",
    "# 1) `numpy` seed\n",
    "# 2) backend random seed\n",
    "# 3) `python` random seed\n",
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "# If using TensorFlow, this will make GPU ops as deterministic as possible,\n",
    "# but it will affect the overall performance, so be mindful of that.\n",
    "# TODO: this is causing heavy performance hit - see how much different are results without it\n",
    "# tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load everything so that we can split it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 11:38:34.539723: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:396] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-09-24 11:38:35.148871: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "if (DATASET_SOURCE == DatasetSource.TENSORFLOW\n",
    "    or DATASET_SOURCE == DatasetSource.KAGGLE):\n",
    "    ds, info = tfds.load(\n",
    "        \"beans\",\n",
    "        split=\"all\",\n",
    "        with_info=True,\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "    )\n",
    "    ds_all = tfds.as_dataframe(ds, info)\n",
    "    ds_all_images = ds_all[\"image\"]\n",
    "    ds_all_labels = ds_all[\"label\"]\n",
    "\n",
    "    n_classes = info.features[\"label\"].num_classes\n",
    "    class_names = info.features[\"label\"].names\n",
    "\n",
    "elif (DATASET_SOURCE == DatasetSource.HUGGING_FACE):\n",
    "    ds = load_dataset(\"AI-Lab-Makerere/beans\")\n",
    "    ds_all = concatenate_datasets([ds[\"train\"], ds[\"validation\"], ds[\"test\"]])\n",
    "    ds_all_images = ds_all[\"image\"]\n",
    "    ds_all_labels = ds_all[\"labels\"]\n",
    "\n",
    "    class_names = [\"angular_leaf_spot\", \"bean_rust\", \"healthy\"]\n",
    "    n_classes = len(class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified split\n",
    "\n",
    "Original split caused huge difference in performance of model when doing predictions with validation and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 11:38:40.017535: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 3102000000 exceeds 10% of free system memory.\n",
      "2025-09-24 11:38:53.824268: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.89GiB (rounded to 3102000128)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-09-24 11:38:53.824291: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1049] BFCAllocator dump for GPU_0_bfc\n",
      "2025-09-24 11:38:53.824299: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (256): \tTotal Chunks: 11, Chunks in use: 11. 2.8KiB allocated for chunks. 2.8KiB in use in bin. 136B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824303: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824308: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824311: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824315: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824318: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824321: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824324: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824328: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824331: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824334: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824337: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824341: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 0. 2.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824344: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824348: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824351: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824354: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824363: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824366: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824370: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824373: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-09-24 11:38:53.824378: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1072] Bin for 2.89GiB was 256.00MiB, Chunk State: \n",
      "2025-09-24 11:38:53.824381: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 2097152\n",
      "2025-09-24 11:38:53.824386: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 701a00000 of size 1280 next 1\n",
      "2025-09-24 11:38:53.824389: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 701a00500 of size 256 next 2\n",
      "2025-09-24 11:38:53.824392: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 701a00600 of size 256 next 3\n",
      "2025-09-24 11:38:53.824394: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 701a00700 of size 256 next 4\n",
      "2025-09-24 11:38:53.824397: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 701a00800 of size 256 next 5\n",
      "2025-09-24 11:38:53.824400: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 701a00900 of size 256 next 6\n",
      "2025-09-24 11:38:53.824402: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 701a00a00 of size 256 next 7\n",
      "2025-09-24 11:38:53.824405: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 701a00b00 of size 256 next 8\n",
      "2025-09-24 11:38:53.824408: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 701a00c00 of size 256 next 9\n",
      "2025-09-24 11:38:53.824410: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 701a00d00 of size 256 next 10\n",
      "2025-09-24 11:38:53.824413: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 701a00e00 of size 256 next 11\n",
      "2025-09-24 11:38:53.824416: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 701a00f00 of size 256 next 12\n",
      "2025-09-24 11:38:53.824419: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 701a01000 of size 2093056 next 18446744073709551615\n",
      "2025-09-24 11:38:53.824422: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1110]      Summary of in-use Chunks by size: \n",
      "2025-09-24 11:38:53.824426: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 11 Chunks of size 256 totalling 2.8KiB\n",
      "2025-09-24 11:38:53.824429: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2025-09-24 11:38:53.824432: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] Sum Total of in-use chunks: 4.0KiB\n",
      "2025-09-24 11:38:53.824435: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119] Total bytes in pool: 2097152 memory_limit_: 3014446286 available bytes: 3012349134 curr_region_allocation_bytes_: 4194304\n",
      "2025-09-24 11:38:53.824441: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1124] Stats: \n",
      "Limit:                      3014446286\n",
      "InUse:                            4096\n",
      "MaxInUse:                         4096\n",
      "NumAllocs:                          15\n",
      "MaxAllocSize:                     1280\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-09-24 11:38:53.824445: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] *___________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      1\u001b[39m train_data, temp_data, train_labels, temp_labels = train_test_split(\n\u001b[32m      2\u001b[39m     ds_all_images,\n\u001b[32m      3\u001b[39m     ds_all_labels,\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     stratify=ds_all_labels,\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m val_data, test_data, val_labels, test_labels = train_test_split(\n\u001b[32m     11\u001b[39m     temp_data,\n\u001b[32m     12\u001b[39m     temp_labels,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     stratify=temp_labels,\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m ds_train = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m ds_valid = tf.data.Dataset.from_tensor_slices((np.array(val_data.tolist(), dtype=np.float32), np.array(val_labels.tolist(), dtype=np.float32)))\n\u001b[32m     21\u001b[39m ds_test = tf.data.Dataset.from_tensor_slices((np.array(test_data.tolist(), dtype=np.float32), np.array(test_labels.tolist(), dtype=np.float32)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:827\u001b[39m, in \u001b[36mDatasetV2.from_tensor_slices\u001b[39m\u001b[34m(tensors, name)\u001b[39m\n\u001b[32m    823\u001b[39m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[32m    824\u001b[39m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[32m    825\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_from_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[39m, in \u001b[36m_from_tensor_slices\u001b[39m\u001b[34m(tensors, name)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_tensor_slices\u001b[39m(tensors, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:33\u001b[39m, in \u001b[36m_TensorSliceDataset.__init__\u001b[39m\u001b[34m(self, element, is_files, name)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files=\u001b[38;5;28;01mFalse\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     32\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m   element = \u001b[43mstructure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m   batched_spec = structure.type_spec_from_value(element)\n\u001b[32m     35\u001b[39m   \u001b[38;5;28mself\u001b[39m._tensors = structure.to_batched_tensor_list(batched_spec, element)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/data/util/structure.py:134\u001b[39m, in \u001b[36mnormalize_element\u001b[39m\u001b[34m(element, element_signature)\u001b[39m\n\u001b[32m    131\u001b[39m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    132\u001b[39m         dtype = \u001b[38;5;28mgetattr\u001b[39m(spec, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    133\u001b[39m         normalized_components.append(\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m             \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m%\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m nest.pack_sequence_as(pack_as, normalized_components)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/profiler/trace.py:183\u001b[39m, in \u001b[36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, **trace_kwargs):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:757\u001b[39m, in \u001b[36mconvert_to_tensor\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[32m    756\u001b[39m preferred_dtype = preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[39m\n\u001b[32m    225\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    226\u001b[39m           _add_error_prefix(\n\u001b[32m    227\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m for type \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret.dtype.base_dtype.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    231\u001b[39m               name=name))\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m   ret = \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[32m    237\u001b[39m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/framework/constant_tensor_conversion.py:29\u001b[39m, in \u001b[36m_constant_tensor_conversion_function\u001b[39m\u001b[34m(v, dtype, name, as_ref)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[32m     28\u001b[39m _ = as_ref\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[39m, in \u001b[36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    141\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[39m, in \u001b[36mconstant\u001b[39m\u001b[34m(value, dtype, shape, name)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m\"\u001b[39m, v1=[])\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconstant\u001b[39m(\n\u001b[32m    179\u001b[39m     value, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, shape=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[33m\"\u001b[39m\u001b[33mConst\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m ) -> Union[ops.Operation, ops._EagerTensorBase]:\n\u001b[32m    181\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[32m    182\u001b[39m \n\u001b[32m    183\u001b[39m \u001b[33;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[39m, in \u001b[36m_constant_impl\u001b[39m\u001b[34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[39m\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m trace.Trace(\u001b[33m\"\u001b[39m\u001b[33mtf.constant\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    288\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m const_tensor = ops._create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    292\u001b[39m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[32m    293\u001b[39m )\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[39m, in \u001b[36m_constant_eager_impl\u001b[39m\u001b[34m(ctx, value, dtype, shape, verify_shape)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_constant_eager_impl\u001b[39m(\n\u001b[32m    298\u001b[39m     ctx, value, dtype, shape, verify_shape\n\u001b[32m    299\u001b[39m ) -> ops._EagerTensorBase:\n\u001b[32m    300\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m   t = \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[39m, in \u001b[36mconvert_to_eager_tensor\u001b[39m\u001b[34m(value, ctx, dtype)\u001b[39m\n\u001b[32m    106\u001b[39m     dtype = dtypes.as_dtype(dtype).as_datatype_enum\n\u001b[32m    107\u001b[39m ctx.ensure_initialized()\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mInternalError\u001b[39m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "train_data, temp_data, train_labels, temp_labels = train_test_split(\n",
    "    ds_all_images,\n",
    "    ds_all_labels,\n",
    "    train_size=TRAIN_SIZE,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=ds_all_labels,\n",
    ")\n",
    "\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(\n",
    "    temp_data,\n",
    "    temp_labels,\n",
    "    train_size=VAL_SIZE,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=temp_labels,\n",
    ")\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((np.array(train_data.tolist()), np.array(train_labels.tolist())))\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices((np.array(val_data.tolist()), np.array(val_labels.tolist())))\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((np.array(test_data.tolist()), np.array(test_labels.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure original ratio is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train set {len(list(ds_train))}\")\n",
    "print(f\"validation set {len(list(ds_valid))}\")\n",
    "print(f\"test set {len(list(ds_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that ratio of different classes is same across datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(dataset):\n",
    "    label_counts = collections.Counter()\n",
    "\n",
    "    for _, label in dataset:\n",
    "        label_counts[label.numpy()] += 1\n",
    "\n",
    "    total_count = sum(label_counts.values())\n",
    "    label_ratios = {label: count / total_count for label, count in label_counts.items()}\n",
    "    \n",
    "    sorted_label_ratios = dict(sorted(label_ratios.items()))\n",
    "\n",
    "    return sorted_label_ratios\n",
    "\n",
    "print(count_labels(ds_train))\n",
    "print(count_labels(ds_valid))\n",
    "print(count_labels(ds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Sequential([\n",
    "    Resizing(height=224, width=224, crop_to_aspect_ratio=True),\n",
    "    Lambda(preprocess_input)\n",
    "])\n",
    "\n",
    "# TODO: instead of augmenting existing sample - try creating new ones with augmentation\n",
    "# (not too many since that can cause overfitting as well)\n",
    "# TODO: test more augmentations (that make sense) and different parameters (e.g. zoom, brightness, noise)\n",
    "preprocess_and_augmentation = Sequential([\n",
    "    Resizing(height=224, width=224, crop_to_aspect_ratio=True),\n",
    "    RandomFlip(mode=\"horizontal\", seed=42),\n",
    "    RandomRotation(factor=0.05, seed=42),\n",
    "    RandomContrast(factor=0.2, seed=42),\n",
    "    Lambda(preprocess_input)\n",
    "])\n",
    "augmentation = Sequential([\n",
    "    RandomFlip(mode=\"horizontal\", seed=42),\n",
    "    RandomRotation(factor=0.05, seed=42),\n",
    "    RandomContrast(factor=0.2, seed=42),\n",
    "])\n",
    "\n",
    "resizing_and_augmentation = Sequential([\n",
    "    Resizing(height=224, width=224, crop_to_aspect_ratio=True),\n",
    "    RandomFlip(mode=\"horizontal\", seed=42),\n",
    "    RandomRotation(factor=0.05, seed=42),\n",
    "    RandomContrast(factor=0.2, seed=42)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess and augmentation is part of input pipeline because it is faster.\n",
    "\n",
    "When processing power / time is not an issue, I recommend moving it to model.\n",
    "Apart from cleaner and more flexible code, having it as part of model actually improved performance a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not PREPROCESS_IN_MODEL):\n",
    "    ds_train = ds_train.map(\n",
    "        lambda X, y: (preprocess(X), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache(\"cache_train\")\n",
    "ds_train = ds_train.shuffle(TRAIN_SIZE)\n",
    "if (not PREPROCESS_IN_MODEL):\n",
    "    ds_train = ds_train.map(\n",
    "        lambda X, y: (augmentation(X), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not PREPROCESS_IN_MODEL):\n",
    "    ds_valid = ds_valid.map(\n",
    "        lambda X, y: (preprocess(X), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_valid = ds_valid.cache(\"cache_val\")\n",
    "ds_valid = ds_valid.batch(BATCH_SIZE)\n",
    "ds_valid = ds_valid.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not PREPROCESS_IN_MODEL):\n",
    "    ds_test = ds_test.map(\n",
    "        lambda X, y: (preprocess(X), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.cache(\"cache_test\")\n",
    "ds_test = ds_test.batch(BATCH_SIZE)\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that augmentation produces photos similar to original dataset (too much augmentation might cause model not to generalize well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "for X_batch, y_batch in ds_train.take(1):\n",
    "    # TODO: make sure we get clear augmented and original images even if preprocessing in model\n",
    "    # X_batch = resizing_and_augmentation(X_batch)\n",
    "    # X_batch = preprocess_input(X_batch)\n",
    "    for index in range(9):\n",
    "        plt.subplot(3, 3, index + 1)\n",
    "        plt.imshow((X_batch[index] + 1) / 2)  # rescale to 0–1 for imshow()\n",
    "        plt.title(f\"Class: {class_names[y_batch[index]]}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model with pre-trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Create a separate README for experiment results / conclusions\n",
    "\n",
    "Xception with SGD optimizer converges pretty quickly with good results (other models needed more time with lower learning to achieve same performance).\n",
    "\n",
    "This version mostly follows example from [Machine Learning Notebooks, 3rd edition](https://github.com/ageron/handson-ml3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BASE_MODEL == BaseModel.XCEPTION:\n",
    "    base_model = Xception(input_shape=(224, 224, 3), include_top=False)\n",
    "elif BASE_MODEL == BaseModel.EFFICIENT_NET_V2:\n",
    "    base_model = EfficientNetV2S(input_shape=(224, 224, 3), include_top=False)\n",
    "elif BASE_MODEL == BaseModel.MOBILE_NET:\n",
    "    base_model = MobileNet(input_shape=(224, 224, 3), include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple top performs surprisingly well (however Dropout is needed for overfitting). \n",
    "\n",
    "Adding additional Dense layer, Batch Normalization layer and/or Dropout layer required more hyperparameter tuning to get similar performance (but never as good.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (PREPROCESS_IN_MODEL):\n",
    "    inputs = Input(shape=(None, None, 3))\n",
    "    x = resizing_and_augmentation(inputs)\n",
    "    x = preprocess_input(x)\n",
    "    x = base_model(x, training=False)\n",
    "else:\n",
    "    inputs = base_model.input\n",
    "    x = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# TODO: test different dropout\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# TODO: test kernel_regularizer\n",
    "outputs = Dense(n_classes, activation=\"softmax\")(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using base_model layers directly (base_model.output), we need to iterate through all of them and switch training off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When preprocessing is done in model, we do not need to set trainable flag per base layer\n",
    "if PREPROCESS_IN_MODEL:\n",
    "    base_model.trainable = False\n",
    "else:\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial training without touching base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping is here in this version more to make sure that the best weights are used.\n",
    "\n",
    "In different versions where we needed to train for longer, it also helped us to end early when there was not progress (and avoid overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, restore_best_weights=True, mode=\"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"model_checkpoint.keras\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD works surprisingly well - doesn't use as much memory, converges fast and with good results.\n",
    "\n",
    "Adam required more training and had bigger memory footprint with much smaller learning rate (and/or learning rate scheduler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Optimizer.SGD:\n",
    "    optimizer = SGD(learning_rate=0.1, momentum=0.9)\n",
    "elif Optimizer.Adam:\n",
    "    optimizer = Adam()\n",
    "elif OPTIMIZER == Optimizer.NADAM:\n",
    "    optimizer = Nadam(learning_rate=1e-4)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import psutil\n",
    "\n",
    "class RAMMonitor(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()  # Force garbage collection\n",
    "        ram_percent = psutil.virtual_memory().percent\n",
    "        print(f\"Epoch {epoch}: RAM usage {ram_percent:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=EPOCHS_PRETRAIN,\n",
    "    callbacks=[early_stopping, model_checkpoint_callback, RAMMonitor()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_epoch = early_stopping.best_epoch + 1 # EarlyStopping uses 0-based indexing (from observation)\n",
    "restored_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(ds_test, verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_history = history.history[\"accuracy\"]\n",
    "val_acc_history = history.history[\"val_accuracy\"]\n",
    "\n",
    "loss_history = history.history[\"loss\"]\n",
    "val_loss_history = history.history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc_history, label=\"Training Accuracy\")\n",
    "plt.plot(val_acc_history, label=\"Validation Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xticks(range(100))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim([min(plt.ylim()), max(plt.ylim())])\n",
    "plt.plot([restored_epoch - 1, restored_epoch - 1], plt.ylim(), label=\"Best weights\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss_history, label=\"Training Loss\")\n",
    "plt.plot(val_loss_history, label=\"Validation Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xticks(range(100))\n",
    "plt.ylabel(\"Cross Entropy\")\n",
    "plt.ylim([min(plt.ylim()), max(plt.ylim())])\n",
    "plt.plot([restored_epoch - 1, restored_epoch - 1], plt.ylim(), label=\"Best weights\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before - early stopping is used mostly to get best weights.\n",
    "\n",
    "Using bigger number for patience as we fine tune for longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, restore_best_weights=True, mode=\"min\"\n",
    ")\n",
    "\n",
    "# TensorBoard Callback (repeating here to have unique timestamp)\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: test different learning rate schedules (e.g. one cycle scheduler, ReduceLROnPlateau)\n",
    "lr_schedule = CosineDecayRestarts(\n",
    "    initial_learning_rate=1e-4,  # Adjust if needed\n",
    "    first_decay_steps=20,        # Increased from 10\n",
    "    t_mul=2.0,                   # You can try increasing this\n",
    "    m_mul=1.0,                   # You can experiment with values < 1.0\n",
    "    alpha=0.0                    # Adjust if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfreeze some layers from base_model for fine tuning. We also need to use much lower learning rate so that existing weights are not completely destroyed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_IN_MODEL:\n",
    "    base_model.trainable = True\n",
    "\n",
    "    for layer in base_model.layers[:-226]:\n",
    "        layer.trainable = False\n",
    "else:\n",
    "    for layer in base_model.layers[56:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "if OPTIMIZER == Optimizer.SGD:\n",
    "    # TODO: test lr schedule for SGD as well (different learning rates though)\n",
    "    optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "elif OPTIMIZER == Optimizer.ADAM:\n",
    "    optimizer = Adam(learning_rate=lr_schedule)\n",
    "elif OPTIMIZER == Optimizer.NADAM:\n",
    "    # TODO: test lr schedule for NADAM as well (different learning rates though)\n",
    "    optimizer = Nadam(learning_rate=1e-4)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_fine = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=EPOCHS_FINETUNE,\n",
    "    callbacks=[early_stopping, tensorboard_callback, model_checkpoint_callback, RAMMonitor()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_epoch_fine = early_stopping.best_epoch + 1 # EarlyStopping uses 0-based indexing (from observation)\n",
    "restored_epoch_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(ds_train, verbose=2)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(ds_valid, verbose=2)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(ds_test, verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dismiss history that was not used (Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_history = acc_history[:restored_epoch]\n",
    "val_acc_history = val_acc_history[:restored_epoch]\n",
    "\n",
    "loss_history = loss_history[:restored_epoch]\n",
    "val_loss_history = val_loss_history[:restored_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_history += history_fine.history[\"accuracy\"]\n",
    "val_acc_history += history_fine.history[\"val_accuracy\"]\n",
    "\n",
    "loss_history += history_fine.history[\"loss\"]\n",
    "val_loss_history += history_fine.history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc_history, label=\"Training Accuracy\")\n",
    "plt.plot(val_acc_history, label=\"Validation Accuracy\")\n",
    "plt.xticks(range(100))\n",
    "plt.ylim([min(plt.ylim()), max(plt.ylim())])\n",
    "plt.plot(\n",
    "    [restored_epoch - 1, restored_epoch - 1], plt.ylim(), label=\"Start Fine Tuning\"\n",
    ")\n",
    "plt.plot(\n",
    "    [\n",
    "        restored_epoch + restored_epoch_fine - 1,\n",
    "        restored_epoch + restored_epoch_fine - 1,\n",
    "    ],\n",
    "    plt.ylim(),\n",
    "    label=\"Best weights\",\n",
    ")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss_history, label=\"Training Loss\")\n",
    "plt.plot(val_loss_history, label=\"Validation Loss\")\n",
    "plt.xticks(range(100))\n",
    "plt.ylim([min(plt.ylim()), max(plt.ylim())])\n",
    "plt.plot(\n",
    "    [restored_epoch - 1, restored_epoch - 1], plt.ylim(), label=\"Start Fine Tuning\"\n",
    ")\n",
    "plt.plot(\n",
    "    [\n",
    "        restored_epoch + restored_epoch_fine - 1,\n",
    "        restored_epoch + restored_epoch_fine - 1,\n",
    "    ],\n",
    "    plt.ylim(),\n",
    "    label=\"Best weights\",\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"beans_disease_classification_transfer_learning.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = datetime.datetime.now() - start_time\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify that config prevailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.mixed_precision.global_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in tf.config.list_physical_devices('GPU'):\n",
    "    print(gpu)\n",
    "    if tf.config.experimental.get_device_details(gpu):\n",
    "        print(tf.config.experimental.get_device_details(gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"Memory growth enabled: {tf.config.experimental.get_memory_growth(gpus[0])}\")\n",
    "    \n",
    "    # Also check current memory usage\n",
    "    try:\n",
    "        memory_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "        print(f\"Current: {memory_info['current']/1024**3:.2f}GB\")\n",
    "        print(f\"Peak: {memory_info['peak']/1024**3:.2f}GB\")\n",
    "    except:\n",
    "        print(\"Memory info not available during execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model for mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"beans_disease_classification_transfer_learning.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model on Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class_names = {\n",
    "    0 : \"Angular Leaf\",\n",
    "    1 : \"Bean Rust\",\n",
    "    2 : \"Healthy\"\n",
    "}\n",
    "\n",
    "# Path to local samples\n",
    "samples_dir = \"hugging_face/samples\"\n",
    "\n",
    "# Get all sample images\n",
    "sample_files = [f for f in os.listdir(samples_dir) if f.endswith(('.jpg', '.png'))]\n",
    "sample_files.sort()  # Sort for consistent ordering\n",
    "\n",
    "print(f\"Found {len(sample_files)} sample images: {sample_files}\")\n",
    "\n",
    "# Create a mapping from filename to expected class\n",
    "filename_to_class = {\n",
    "    \"angular_leaf_spot_01.jpg\": 0,  # angular_leaf_spot\n",
    "    \"bean_rust_01.jpg\": 1,          # bean_rust  \n",
    "    \"healthy_01.jpg\": 2,             # healthy\n",
    "}\n",
    "\n",
    "# Test inference on all sample images\n",
    "fig, axes = plt.subplots(1, len(sample_files), figsize=(15, 5))\n",
    "if len(sample_files) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, filename in enumerate(sample_files):\n",
    "    # Load image\n",
    "    img_path = os.path.join(samples_dir, filename)\n",
    "    sample_image = Image.open(img_path).convert(\"RGB\")\n",
    "    true_label = filename_to_class.get(filename, -1)\n",
    "    \n",
    "    # Resize image to model input size\n",
    "    sample_image_resized = sample_image.resize((224, 224))\n",
    "    \n",
    "    # Display the image\n",
    "    axes[idx].imshow(sample_image_resized)\n",
    "    axes[idx].set_title(f\"{filename}\\nTrue: {class_names[true_label] if true_label != -1 else 'Unknown'}\")\n",
    "    axes[idx].axis(\"off\")\n",
    "    \n",
    "    # Preprocess for inference\n",
    "    img_array = np.array(sample_image_resized)\n",
    "    img_batch = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    preprocessed_img = preprocess(img_batch)\n",
    "    \n",
    "    # Perform inference\n",
    "    predictions = model.predict(preprocessed_img, verbose=0)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    confidence = np.max(predictions[0])\n",
    "    \n",
    "    print(f\"\\n--- {filename} ---\")\n",
    "    print(f\"True label: {class_names[true_label] if true_label != -1 else 'Unknown'}\")\n",
    "    print(f\"Predicted label: {class_names[predicted_class]}\")\n",
    "    print(f\"Confidence: {confidence:.4f}\")\n",
    "    print(f\"Correct: {'✓' if predicted_class == true_label else '✗'}\")\n",
    "    print(f\"Prediction probabilities:\")\n",
    "    for i, prob in enumerate(predictions[0]):\n",
    "        print(f\"  {class_names[i]}: {prob:.4f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Keras model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Optional: Enable optimizations for smaller model size\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Force float32 input/output types for compatibility\n",
    "converter.target_spec.supported_types = [tf.float32]\n",
    "converter.inference_input_type = tf.float32\n",
    "converter.inference_output_type = tf.float32\n",
    "\n",
    "# Enable Select TF Ops fallback for unsupported ops (required for Xception)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS     # enable TensorFlow ops.\n",
    "]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "with open('beans_disease_classification_transfer_learning.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TensorFlow Lite model saved as 'beans_disease_classification_transfer_learning.tflite'\")\n",
    "print(f\"Model size: {len(tflite_model) / 1024 / 1024:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
